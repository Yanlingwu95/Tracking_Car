<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<!-- PAGE TITLE -->
<title>Home</title>

<!-- ===================================
	FAVICON ICON
==================================== -->
<link rel="shortcut icon" href="images/favicon.ico">

<!-- ===================================
	NORMALIZE CSS
==================================== -->
<link rel="stylesheet" href="css/normalize.css">

<!-- ===================================
	BOOTSTRAP
==================================== -->
<link rel="stylesheet" href="css/bootstrap.min.css">

<!-- ===================================
	GOOGLE FONTS
==================================== -->
<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Raleway:600,700,400,300' rel='stylesheet' type='text/css'>

<!-- ===================================
	FONTS ICON
==================================== -->
<link rel="stylesheet" href="css/font-awesome/css/font-awesome.css">

<!-- ===================================
	PLUGIN
==================================== -->
<link rel="stylesheet" href="css/magnific-popup.css">
<link rel="stylesheet" href="css/slider-pro.css">
<link rel="stylesheet" href="css/owl.carousel.css">
<link rel="stylesheet" href="css/owl.theme.css">
<link rel="stylesheet" href="css/owl.transitions.css">
<link rel="stylesheet" href="css/animate.css">

<!-- ===================================
	MAIN STYLESHEET
==================================== -->
<link rel="stylesheet" href="css/main.css">
<link rel="stylesheet" href="css/responsive.css" />
<link rel="stylesheet" href="css/color-green.css" id="colors" />



<!--[if lt IE 9]>
	<script src="js/html5shiv.min.js"></script>
	<script src="js/respond.min.js"></script>
	<script type="text/javascript" src="js/selectivizr-min.js"></script>
	<script src="http://s3.amazonaws.com/nwapi/nwmatcher/nwmatcher-1.2.5-min.js"></script>
	<script src="http://css3-mediaqueries-js.googlecode.com/files/css3-mediaqueries.js"></script>
	<script src="http://ie7-js.googlecode.com/svn/version/2.1(beta4)/IE9.js"></script>
<![endif]-->
	<script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
	<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>
		</script>
</head>

<body>
<!-- ===================================
	PRELOADER
==================================== -->
<div class="preloader">
	<div class="status"></div>
</div>

<!-- ===================================
	HEADER
==================================== -->
<header>
	<!-- Navigation Menu start-->
	<nav class="navbar clean-main-menu" role="navigation">
		<div class="container">

			<!-- Navbar Toggle -->
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>

				<!-- Logo -->
				<!-- comment the logo -->
				<a class="navbar-brand" href="index.html"><img class="logo" id="logo" src="images/cornell_logo_small.png" alt="Page"></a>


			</div>
			<!-- Navbar Toggle End -->

			<!-- navbar-collapse start-->
			<div id="nav-menu" class="navbar-collapse collapse" role="navigation">
				<ul class="nav navbar-nav clean-menu-wrapper">
					<li class="active">
						<a href="#clean-slider">Home</a>
					</li>
					<li>
						<a href="#objective">Objective</a>
					</li>
					<li>
						<a href="#about">Introduction</a>
					</li>
					<li>
						<a href="#featured-works">Design</a>
					</li>
					<li>
						<a href="#offer"> Testing and Issue </a>
					</li>
					<li>
						<a href="#pricing">Conclusion</a>
					</li>
					<li>
						<a href="#testimonial">Future Work</a>
					</li>
					<li>
						<a href="#contact">Appendix</a>
					</li>
				</ul>
			</div>
			<!-- navbar-collapse end-->

		</div>
	</nav>
	<!-- Navigation Menu end-->
</header>


<!-- ===================================
	MAIN SLIDER
==================================== -->
<section class="slider-pro clean-slider" id="clean-slider">
	<div class="sp-slides">

		<!-- Slides -->
		<div class="sp-slide clean-main-slides">
			<div class="clean-img-overlay"></div>

			<img class="sp-image" src="images/slider/car1.jpg" alt="Slider 1"/>
			<h1 class="sp-layer clean-slider-text-big" data-position="center" data-show-transition="right" data-hide-transition="right" data-show-delay="1500" data-hide-delay="200"> <span class="clean-color-contras">Autonomous Tracking Robot</span>  </h1>
			<p class="sp-layer"
			data-position="center" data-vertical="15%" data-show-delay="2000" data-hide-delay="200" data-show-transition="left" data-hide-transition="down">
			   Yanling Wu(yw996) | Yeh Tawei(ty359)</p>

		</div>
		<!-- Slides End -->

		<!-- Slides -->
		<div class="sp-slide clean-main-slides">
			<div class="clean-img-overlay"></div>

			<img class="sp-image" src="images/slider/car3.jpg" alt="Slider 3"/>

			<h1 class="sp-layer clean-slider-text-big"
			data-position="center" data-show-transition="right" data-hide-transition="right" data-show-delay="1500" data-hide-delay="200">
			 <span class="clean-color-contras">Tracking Robotic Car </span>
			</h1>

			<p class="sp-layer"
			data-position="center" data-vertical="15%" data-show-delay="1000" data-hide-delay="200" data-show-transition="left" data-hide-transition="down">
				Robotic car can track a falling balloon and pop it.
			</p>

		</div>
		<!-- Slides End -->

	</div>
</section>


<!-- ===================================
	OBJECTIVE SECTION
==================================== -->
<section id="objective" class="clean-section-wrapper background-one">
	<div class="container">
		<div class="row">

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">

				<h1><span class="clean-color-contras">Objective </span></h1>
				<div class="clean-line"></div>
				<iframe width="560" height="315" src="https://www.youtube.com/embed/_2IYR1ttT54" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">An autonomous balloon tracking vehicle capable of tracking a balloon and terminating it.  </p>
			</div>
			<!-- Section Header End -->

		</div>
	</div>
</section>





<!-- ===================================
	ABOUT SECTION -- Introduction section
==================================== -->
<section id="about" class="clean-section-wrapper background-one">
	<div class="container">
		<div class="row">

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
				<h1><span class="clean-color-contras">Introduction </span></h1>
				<div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">Based on Raspberry Pi, we create a tracking robot that can track a falling red balloon and try to pop the balloon before it lands. In order to recognize the balloon, we implemented the color detection by OpenCV. The precise and stable locomotive of the robot, which includes camera tilt kit and two DC motors, has been controlled via PID algorithm. Besides, leveraging python’s multiprocessor modules tremendously decreases image processing latency in real-time. </p>
			</div>
			<!-- Section Header End -->

			<!-- What We Do -->
			<div class="clean-what-we-do">
				<a href="#Pi_camera">

					<div class="col-md-3 col-sm-3 col-xs-12 clean-blurb-round-icon wow bounceInLeft">
						<div class="clean-icon">
							<i class="fa fa-html5"></i>
						</div>
						<h3>Pi Camera</h3>
						<p>Object Recognition</p>
					</div>
				</a>

				<a href="#Tilt_kit">
					<div class="col-md-3 col-sm-3 col-xs-12 clean-blurb-round-icon wow bounceIn" data-wow-delay=".5s">
						<div class="clean-icon">
							<i class="fa fa-css3"></i>
						</div>
						<h3>Tilt kit</h3>
						<p>Haedware PWM</p>
					</div>
				</a>

				<a href="#Multiprocessing">
					<div class="col-md-3 col-sm-3 col-xs-12 clean-blurb-round-icon wow bounceIn" data-wow-delay=".5s">
						<div class="clean-icon">
							<i class="fa fa-laptop"></i>
						</div>
						<h3>Multiprocessing</h3>
						<p>Decrease latency</p>
					</div>
				</a>

				<a href="#Controller">
					<div class="col-md-3 col-sm-3 col-xs-12 clean-blurb-round-icon wow bounceInRight" data-wow-delay=".5s">
						<div class="clean-icon">
							<i class="fa fa-support"></i>
						</div>
						<h3>DC motor controller</h3>
						<p>wheels & PID </p>
					</div>
				</a>

			</div>
			<!-- What We Do End -->

		</div>
	</div>
</section>





<!-- ===================================
	FEATURED WORK SECTION -- Design Section
==================================== -->
<section id="featured-works" class="clean-section-wrapper">
	<!-- Container -->
	<div class="container">
		<div class="row">

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
			  <h1><span class="clean-color-contras">Design </span></h1>
			  <div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">Since we only have one Pi camera, we couldn’t measure the distance from the method of two camera. Our solution is to keep the balloon on the center of the image as possible. Therefore, the area would represent as the distance between the balloon and the robot. The Y axis differential would be the rotation error. And the X axis differential would be the tilt error. Consequently, our robot should require the accurate recognition on the balloon.  </p>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">
				To accomplish the project, we have divided it into several smaller tasks and combine them in the end. In general, there are two parts which are hardware and software. And they have different tasks to be tackled in the following introduction.</p>
			</div>
			<!-- Section Header End -->

		</div>
	</div>
	<!-- Container End -->

<!-- ===================================
	SCREENSHOOT --- hardware part
==================================== -->
<section class="clean-custom-sec clean-section-wrapper background-two">
	<div class="container">
		<div class="row">
			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
				<h1><span class="clean-color-contras">Hardware Part</span></h1>
				<div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">`The body of the car. </p>

			</div>
			<!-- Section Header End -->

			<div class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>Overall</h3>
				<p>Our robot, in short, is a differential drive vehicle with a Pi camera on it. Therefore, we would need two motors to drive the robot and a ball bearing keep it balancing. We also need robot frames to hold everything up. Here’s our shot of the robot. </p>

				<br />
				<br />
				<br />

				<h3>1. Self-designed motor bracket</h3>
				<p>Everything is in placed from the previous lab section, except the motor brackets. We self-designed the motor brackets using Solidworks. After several simulation and testing, we would be able to fit the motor with the robot frame properly. </p>
			</div>

			<div id=Controller class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>2. DC motor driver</h3>

				<p>Due to the speed limit, the Parallax continuous rotation servo is replaced by TT DC Gearbox Motor with higher rpm (200RPM). However, unlike Parallax continuous rotation servo, we can’t control the DC motor with PWM commands. The DC motor is powered from 3VDC to 6VDC. The higher voltage, the faster it goes. As a result, we bought a motor driver – “RasPi Robot Board v3”. It could transform the PWM signal into voltage level and thereby control our DC motors. </p>
				<p>The driver is best required with 9VDC input to supply the motors, although a motor only required 5DV input. This is because if the voltage input is lower than 9VDC, the driver could be malfunctioning. Any unexpected result would come out of nowhere and it’s a painful bug to be realized when developing the robot. </p>

				<p>Also, keep in mind that although 6VDC is its maximum speed limit, it is when the DC motor is unloaded. Moreover, the higher voltage it required, the more current it would need as well. In terms of that means it’s more power consumption than normal, and we need to keep changing the batteries for stable speed outcome and high rpm.</p>
			</div>

<!-- Featured Works Slider -->
	<div class="container-fluid">
		<div class="row-fluid">

			<div class="clean-portfolio-work-slider-section wow fadeIn" data-wow-duration="2s">
				<div id="featured-work-slider" class="owl-carousel clean-portfolio-works-slider">
					<!-- Work 1 -->
					<div class="clean-portfolio-work-item">

						<img src="images/featured-work/1.png" alt="Feature Work 1">
						<div class="clean-port-work-details">
							<ul class="clean-work-meta">
								<li class="clean-lighbox"><a href="images/featured-work/1.png" class="clean-featured-work-img"><i class="fa fa-cog"></i></a></li>
							</ul>
						</div>

					</div>
					<!-- Work 1 End -->

					<!-- Work 2 -->
					<div class="clean-portfolio-work-item">

						<img src="images/featured-work/2.png" alt="Feature Work 2">
						<div class="clean-port-work-details">
							<ul class="clean-work-meta">
								<li class="clean-lighbox"><a href="images/featured-work/2.png" class="clean-featured-work-img"><i class="fa fa-cog"></i></a></li>
							</ul>
						</div>

					</div>
					<!-- Work 2 End -->

					<!-- Work 3 -->
					<div class="clean-portfolio-work-item">

						<img src="images/featured-work/3.png" alt="Feature Work 3">
						<div class="clean-port-work-details">
							<ul class="clean-work-meta">
								<li class="clean-lighbox"><a href="images/featured-work/3.png" class="clean-featured-work-img"><i class="fa fa-cog"></i></a></li>
							</ul>
						</div>

					</div>
					<!-- Work 3 End -->

					<!-- Work 4 -->
					<div class="clean-portfolio-work-item">

						<img src="images/featured-work/4.png" alt="Feature Work 4">
						<div class="clean-port-work-details">
							<ul class="clean-work-meta">
								<li class="clean-lighbox"><a href="images/featured-work/4.png" class="clean-featured-work-img"><i class="fa fa-cog"></i></a></li>
							</ul>
						</div>

					</div>
					<!-- Work 4 End -->
				</div>
			</div>
		</div>
	</div>
			</div>
		</div>
</section>

<!-- ===================================
	SCREENSHOOT --- software part
==================================== -->
<section class="clean-custom-sec clean-section-wrapper background-two">
	<div class="container">
		<div class="row">
			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
				<h1><span class="clean-color-contras">Software Part</span></h1>
				<div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">The organ of the car. </p>
			</div>
			<!-- Section Header End -->

			<div id=Pi_camera class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>1.Object Recognition Algorithm</h3>
				<p>Our object recognition algorithm could detect the red objects videoed by the Pi camera and calculate the center position. The usage of the OpenCV library makes the algorithm easy to implement. First of all, we install the openCV library into our Raspberry Pi. There are some ways to install the openCV library. The easiest and direct method is to run the command “sudo apt-get install libopencv-dev python-opencv” in the command prompt, which can help us to save several hours to compile the openCV. The version of our installed openCV is '2.4.9.1'. After installing the openCV successfully, we need to assemble the Pi camera onto the R-Pi and set it up in configuration of R-Pi. As for the design of the recognition algorithm, it can be broken up into following parts. </p>

				<p>
				<ol><li>
					Create a video capture object of openCV which can take picture at real time by running “cv2.VideoCapture(0)” and when using “cap.read()”, it will return 640*480*3 picture array, which is the default resolution and can fit our requirement of recognition. Three channels is (R, G, B) color space.
					</li>

					<li>
					Run “cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)” can convert the image from RGB color space to HSV (hue, Saturation, Value) color space. We can benefit from this conversion because we need to threshold the HSV image to get the binary image which only keep the red balloon part by setting the low_red and upper_red threshold and it is convenient and easy for us to adjust the threshold in HSV color space.
					</li>

					<li>
					We set the lower_red is (156, 100, 40) and the upper_red is (180, 255, 255). Use the syntax of “maks = cv2.inRange(hsv, low_red, upper_red)” to do threshold. It will make the pixel values that are less than lower_red and more than upper_red equal to zero and the pixel values that are in between them equal to 255.
					</li>

					<li>
					We also use the techniques of computer vision to process the binary images including do “cv2.morphologyEx” of open and close to filter the background noise and make the boundary of binary image smooth and clear.
					</li>

					<li>Run “cv2.findContours(mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)” to do the most important thing which is extract the boundary of the object. If it detects the boundary, it will return a list that contains several calculated contours although most of them are zero. If it does not, it will return a empty list.
					</li>

					<li>
					We need to pick up the longest contour from returned contour list. The method we used is to calculate the area of every contour and find the maximum value that is what we want. Then, calculate the spatial moment that can compute the center position of the object and the area of the objects.
					</li>
				</ol>
				</p>

				<br />i

				<h3>2.Prediction Algorithm: </h3>
				<p>When balloon quickly moved and get rid of the range that the camera can video, the servo of camera will not know how to move and it will be stuck. To solve this problem, we create the prediction algorithm. Prediction Algorithm is to make the servo move at the speed that is slower than the original speed but the same direction. “Original speed” is the speed of car before the balloon disappears. This is reasonable because the balloon is falling and we assume there is no wind to affect the balloon’s motion. </p>

			<br />

			<h3>3.Pygame interface </h3>
				<p>There are three modes in tracking robotic car. We use pygame library to implement visual interface to control them as the following picture shown. </p>
				<p>
					<li>
					The first mode is calibration mode, which is to find the balloon at the beginning in case the person who toss the balloon standing behind the car and it will not see the balloon.
					</li>

					<li>
					The second mode is play mode, which is main program to realize our function. When a person toss a red balloon, the car will track the balloon until it explodes the balloon.
					</li>

					<li>
					The third mode is celebration mode, which makes the car turn around and move forward and backward like a puppy.
					</li>
				</p>
			<img src="images/slider/pygame_interface.png" alt="pygame interface" height="300" width="400">

			</div>

			<div class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>4.PID control Algorithm:</h3>

				<p>
				Our objective is to make the balloon as center as possible. From the respective of the image input, the size of the image is 640*480 and thus the center of the image should be (320, 240). The image processing would recognize the red balloon, find out the contour, and calculate the center point and area.
				</p>

				<p>Given the balloon’s coordinates and the area, which is the system output, we would be able to control the robot with a closed loop controller. To make a simple closed loop controller, we choose PID controller. The benefits are one that it is simple, and second it is robust enough for our robot.
				</p>
				<p>PID algorithm is a closed loop control algorithm. PID stands for proportional-integral-derivative. It takes the present error, past error, and the future error as inputs to make appropriate control and thus reduce the error.
				</p>

				<p>
				\(
				K_i = \frac{K_p}{T_i}, K_d = K_p T_d
				\)

				<br/>
				<br/>
				\(
				u(t) = K(e(t) + \frac{1}{T_i} \int_{t}^{0} e(\tau) d\tau + T_d \frac{de(t)}{dt} )
				\)
				</p>

				<li> P-term: proportional to the error. </li>
				<li> I-term : proportional to the integral of the error, </li>
				<li> D-term: proportional to the derivative of the error. </li>
				<p>
				Actually, not all PID controller used up three terms. To be more specific, the there are controllers like
				</p>
				<li> PD controller, which Ti is unbounded. </li>
				<li> PI controller, which Td is zero. </li>
				<li> P controller, which Ti is unbounded and Td is zero. </li>

				<p>
				Ti is the period of the integration time, and Td is the period of the oscillation time. </p>
				<p>
				For the reason that I-term is generally considered as dangerous when implementing PID controller, we only choose P controller and PD controller.  </p>
				<p>
				So how do we actually control our robot with PID controller? We have three degree of freedom, which is the tilt motor for the camera, the forward velocity for the robot, and the rotation of the robot. The robot has a constraint on side ways that it couldn’t move directly to the left or right. Thus, we overcome this problem by rotating the robot with motor rotating in the opposite direction. The forward and backward velocity is depending on the balloon area shown on the image. The rotation of the robot is depending on the X axis differential of from the image center. The camera tile motor is depending on the Y axis differential of from the image center.
				</p>
			</div>

			<div id=Multiprocessing class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>5. Multiprocessing Algorithm:</h3>
				<p>To achieve our goal of tracking a falliing and moving balloon and pop it, we must decrease the latency and running time of every part as far as possible. At the beginning, the recognition and the course of sending order to control the motors and servo took about 105ms, which means it only processed less than ten pictures every second and it is far away from what we should do since we need to track the moving object and we only have limited time to decide the car’s movement. This delay time is too long. To reduce the delay time, one solution is to parallel process different task because of four cores in R-Pi, we can assign four jobs into four cores. In python, we could use the multiprocessing library to fully take advantage of four cores of R-Pi. </p>
				<p><ol>
					<li>The first core is used to focus on capturing the video and put the image it reads into the “send_frame_queue”, whose minimum running time is 33 ms because the frequency of the Pi camera taking video is 30 fps. </li>

					<li>The second core is used to get the frame of images from send_frame_queue and process the images and extract the contours. Then put the contours into receive_contour_queue, which takes about 10 ms at most.
					</li>

					<li>
					The third core could get the contour from receive_contour_queue and compute the center position and area of the object and implement the PID control algorithm and control the motors of wheels. Since we set the sleep time to 20 ms when controlling the DC motors. In addition, it should put the parameters of controlling servo of camera into send_motor_queue. And the maximum running time of this processor is 22 ms.
					</li>

					<li>
					The forth core can get the parameters to control the tilt kit from send_motor_queue and realize prediction function to ensure the smooth movement of tilt kit , whose maximum running time is 25 ms.
					</li>
				</ol>
				</p>

				<p>This describes the tasks that every core executes and the time they spend. The longest time is up to the frequency of the Pi camera, which is unchangeable to some degree. So this multiprocessing system has optimized the entire program and decrease the running time every loop from 105 ms to 34 ms. Note that the “print” syntax will cause the delay and if wanting show the image onto the monitors, it will increase delay time. </p>
			</div>
		</div>
	</div>
</section>


<!-- ===================================
	OFFER SECTION ---Testing and issues
==================================== -->
<section id="offer" class="clean-section-wrapper clean-offer-section  background-two">
	<div class="container">
		<div class="row">

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
				<h1><span class="clean-color-contras">Testing and Issues</span></h1>
			</div>
		</div>
	</div>
</section>
		<!-- Section Header End -->

<!-- ===================================
	SCREENSHOOT --- Issue
==================================== -->
<section class="clean-custom-sec clean-section-wrapper background-two">
	<div class="container">
		<div class="row">
				<div class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>1. C++ OpenCV install</h3>
				<p>
				Since our robotic car need to track the falling balloon and move to the landing location very fast and considering that python is a kind of interpreted programming language and C++ is a complied programming language, we initially planned to install C++ version of openCV. We tried to install the C++ OpenCV library several times and every time it took more than three hours to compile it. We finally installed the C++ openCV successfully but when we tried to run some codes, it failed and said that it cannot open the Pi camera, which took us about one week. After discussion with Professor Skovira, we decide to use python openCV first and see whether it can meet our requirement. But we will still introduce how to install C++ openCV here briefly.
				<ol>
					<li>
						First of all, we need to install several required packages that we have not installed before such as CMake 2,8,7 or higher, Git, GCC and GTK+2.x or higher, including headers (libgtk2.0-dev). These packages can be installed in a terminal directly.
					</li>

					<li>
					Secondly, OpenCV Source Code is needed which can download from the Git Repository by the command “cd ~/[my_working_directory] git clone https://github.com/opencv/opencv.git git clone https://github.com/opencv/opencv_contrib.git”
					</li>

					<li>
					Thirdly, Building OpenCV from Source using CMake.
						<ol>
							<li>
							Create a temporary directory, where we want to put the generated Makefiles, project files as well as output file and enter there.
							</li>

							<li>
							Configure it by running “cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..”, which will take more than ten minutes.
							</li>

							<li>
							After finishing this, we need to describe some parameters or during the process of compiling, there will be some errors.
							</li>

							<li>
							From build directory execute “make -j7 # runs 7 jobs in parallel”.
							</li>

							<li>
							Install the library by execute “sudo make install” form build directory.
							</li>
						</ol>
					</li>
					</ol>
					</p>
				<p>
					It should work, but there will definitely be a lot of errors. Good Luck!
				</p>
			</div>

			<div class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>2.Pi Camera Setting</h3>
				<p>After python OpenCV library installed, we tried to run testing code, there is one error saying “OpenCV Error: Assertion failed (scn == 3 || scn == 4) in cvtColor, file /build/opencv-U1UwfN/opencv-2.4.9.1+dfsq1/modules/imgproc/src/color.cpp, line 3737”. We searched it on Google, this error can be fixed by running “sudo modprobe bcm2835-v4l2“, which is used to intall the v412 driver on the bcm2835. We thought it is one time install but when the R-Pi reboot, the same error appeared again. Therefore, we add this command into /etc/modules. Then, it can work smoothly.</p>
			</div>

			<div id=Tilt_kit class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>3. Hardware PWM</h3>
				<p>To control the servo of pan tilt kit, under the recommendation of Professor Skovira, we use the hardware PWM to generate control signal instead of software PWM, this is because the signal generated by hardware PWM is stable and less noise in a R-Pi multiprocessing environment. When we following the instruction of the professor to build the hardware PWM file and connect the circuit, we cannot send any signal to the GPIO pin. After asking other students who have experience to implement the hardware PWM, we know some very significant points. One is only GPIO pin 12 and pin 13 can be used to generated hardware PWM signal. Another is before running the code, we need to run “sudo pigpiod” to launch the pigpio library as a daemon. </p>
			</div>

			<div class="col-md-6 col-sm-6 col-xs-12 clean-custom-sec-text wow bounceInRight">
				<h3>4. DC controller</h3>
				<p>Because of tracking and chasing the falling balloon, we need to faster motors to drive the robotic car and thus, with the help of the professor Skovira, we decide to use the DC motor to drive and buy DC controller to control two DC motor to move. It works well but we found that once we add the controller program into multiprocessing, the whole program will be stuck and the queue will keep a lot of unprocessed data. After we monitored the running time of every core, we noticed that the every running time of the third core which is used to process the PID control algorithm and send order to DC controller is far longer than others and the average running time is 202 ms. At first, we thought this could be the problem of the hardware because of the delay of opening motors or the bad connection of circuit to make the transmitting slow. But when we check everything about the circuit, there is no bad connection. So we searched the software stuff. We found there is a syntax about “time.sleep(0.2)” in the library that is used to control the DC controller and this is probably the reason why it runs so slowly. So we changed the source of the library and compile it again. It worked, the running time of the third core decreased to 22 ms. </p>
			</div>
		</div>
	</div>
</section>


<!-- ===================================
	Result and Conclusion SECTION
==================================== -->
<section id="pricing" class="clean-pricing-section">
	<div class="container">
		<div class="row">

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
			  <h1><font color="#7cd552">Result</font></h1>
			  <div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">Initially, we were very concerned about that torque and speed of our motor. Since tossing a ball and catch it before it lands is a hard job to achieve, the robot would require a high speed motor and high speed object detection. To achieve this goal, we were thinking about designing a new gear box with lower reduction ratio. By lowering the reduction ration, the motor would have higher speed but lower torque. It is possible that the new designed gear box wouldn’t work out and ended up consuming us a lot of time. Also, both of us had few knowledges about designing a 3d object, not to mention designing a gear box. As a result, we decided to stay with the original reduction ratio and take the easier task to design the motors’ bracket. </p>
				<br/>
				<br/>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">
				Overall, we approximately meet the goals outlined in the description. Still, there are several changes that allow us to finish the project in a short time. First, rather than installing two cameras for object distance detection, we represent the distance from the object area in an image. Second, rather than catching the balloon into a bucket, we use needles to pop the balloon which would dramatically show the catching result. </p>
			</div>
			<!-- Section Header End -->

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
			  <h1><font color="#7cd552">Conclusion</font></h1>
			  <div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">Lorem ipsum dolor sit amet, consectetur adipisicing elit. Molestiae dolorem nostrum pariatur consequatur aut est aspernatur reiciendis veniam delectus saepe.</p>
			</div>
			<!-- Section Header End -->
		</div>
	</div>
</section>

<!-- ===================================
	Future Work SECTION
==================================== -->
<section id="testimonial" class="clean-pricing-section">
	<div class="container">
		<div class="row">

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
			  <h1><font color="#7cd552">Future Work</font></h1>
			  <div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">We would spend more time on developing the algorithm for estimating an object’s trajectory. Because there were times that the robot couldn’t track the balloon if it suddenly moved away, we would need a trajectory prediction algorithm to overcome this issue. </p>
				<br/>
				<br/>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">
				Also, during tracking mode the robot wasn’t performing its rotation obviously. We would refine the speed controller for faster response when it is moving forward and rotating. </p>
			</div>
			<!-- Section Header End -->

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown">
			  <h1><font color="#7cd552">Acknowledge</font></h1>
			  <div class="clean-line"></div>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">We would spend more time on developing the algorithm for estimating an object’s trajectory. Because there were times that the robot couldn’t track the balloon if it suddenly moved away, we would need a trajectory prediction algorithm to overcome this issue. </p>
				<br/>

			</div>
			<!-- Section Header End -->

		</div>
	</div>
</section>


<!-- ===================================
	Appendix SECTION
==================================== -->
<section id="contact" class="clean-section-wrapper clean-contact-section background-one" data-stellar-background-ratio="0.5">
<div class="clean-parallax-overlay"></div>
	<div class="container">
		<div class="row">

			<!-- Section Header -->
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown clean-section-header-parallax">
				<h1><span class="clean-color-contras">Appendix</span></h1>
				<h2><span class="clean-color-contras"><em>1. Budget</em></span></h2>
				<p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1">
					<table>
						  <thead>
							<tr>
							  <th>Item</th>
							  <th>Unit Cost</th>
							  <th>Quantity</th>
							  <th>Total Cost</th>
							</tr>
						  </thead>
						  <tbody>
							<tr>
							  <td>Line Sensors</td>
							  <td>$3</td>
							  <td>2</td>
							  <td>$6</td>
							</tr>
							<tr>
							  <td>Wall Sensors</td>
							  <td>$7</td>
							  <td>3</td>
							  <td>$21</td>
							</tr>
							<tr>
							  <td>Camera</td>
							  <td>$14</td>
							  <td>1</td>
							  <td>$14</td>
							</tr>
							<tr>
							  <td>Parallax Servos</td>
							  <td>$13</td>
							  <td>2</td>
							  <td>$26</td>
							</tr>
							<tr>
							  <td>Arduino Uno</td>
							  <td>$16</td>
							  <td>1</td>
							  <td>$16</td>
							</tr>
							<tr>
							  <td>Roller Ball Bearing</td>
							  <td>$3</td>
							  <td>1</td>
							  <td>$3</td>
							</tr>
							<tr>
							  <td>LED Strip</td>
							  <td>$2</td>
							  <td>1</td>
							  <td>$2</td>
							</tr>
							<tr>
							  <td>Protoboard</td>
							  <td>$3</td>
							  <td>2</td>
							  <td>$6</td>
							</tr>
							<tr>
							  <td>LM 358 Op Amp</td>
							  <td>$0.16</td>
							  <td>2</td>
							  <td>$0.32</td>
							</tr>
							<tr>
							  <td>Multiplexer</td>
							  <td>$0.26</td>
							  <td>1</td>
							  <td>$0.26</td>
							</tr>
							<tr>
							  <td>Phototransistor</td>
							  <td>$1</td>
							  <td>1</td>
							  <td>$1</td>
							</tr>
							<tr>
							  <td>Electret Microphone</td>
							  <td>$1</td>
							  <td>1</td>
							  <td>$1</td>
							</tr>
							<tr>
							  <td>NRF24L01+ Radio</td>
							  <td>$3</td>
							  <td>1</td>
							  <td>$3</td>
							</tr>
							<tr>
							  <td> </td>
							  <td> </td>
							  <td> </td>
							  <td>$99.58</td>
							</tr>
						  </tbody>
						</table>
					</p>

					<h2><span class="clean-color-contras"><em>2. Code</em></span></h2>
					<p>For more codes, please visit our <a href="https://github.com/yehmostabsurd/XiaoPi_Luck">github</a> page. </p>
				</div>
			<div class="col-md-12 col-sm-12 col-xs-12 clean-section-header wow fadeInDown clean-section-header-parallax">
			  <h1><span class="clean-color-contras">Appendix</span></h1>
			  <h2><span class="clean-color-contras"><em>1. Budget</em></span></h2>
			  <p class="col-md-8 col-sm-10 col-xs-12 col-md-offset-2 col-sm-offset-1"> | Tables        | Are           | Cool  |
			    | ------------- |:-------------:| -----:|
			    | col 3 is      | right-aligned | $1600 |
			    | col 2 is      | centered      |   $12 |
			    | zebra stripes | are neat      |    $1 | </p>
		  </div>
			<!-- Section Header End -->


			</div>
		</div>
	</div>

</section>


<!-- ===================================
	FOOTER SECTION
==================================== -->
<footer class="background-two">
	<div class="container">
		<div class="row">
			<div class="clean-footer-content">

				<div class="clean-footer-logo wow bounceIn" data-wow-offset="0">
					<a href="index.html">
						<img id="logo-footer" src="images/logo.png" alt="clean">
					</a>
				</div>

				<p class="clean-copyright-info">Copyright &copy; 2017.Company name All rights reserved.More Templates <a href="http://www.cssmoban.com/" target="_blank" title="模板之家">模板之家</a> - Collect from <a href="http://www.cssmoban.com/" title="网页模板" target="_blank">网页模板</a></p>

				<ul class="clean-footer-social-info">
					<li>
						<a href=""><i class="fa fa-facebook"></i></a>
					</li>
					<li>
						<a href=""><i class="fa fa-twitter"></i></a>
					</li>
					<li>
						<a href=""><i class="fa fa-google-plus"></i></a>
					</li>
					<li>
						<a href=""><i class="fa fa-linkedin"></i></a>
					</li>
				</ul>

			</div>
		</div>

	</div>
</footer>

<!-- ===================================
	SCRIPTS
==================================== -->
<script src="js/modernizr.min.js"></script>
<script src="js/jquery.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.easing.js"></script>
<script src="js/jquery.scrollUp.min.js"></script>
<script src="js/smooth-scroll.min.js"></script>
<script src="js/jquery.magnific-popup.min.js"></script>
<script src="js/jquery.sliderPro.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.easypiechart.js"></script>
<script src="js/jquery.countTo.js"></script>
<script src="js/isotope.pkgd.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.waypoints.min.js"></script>
<script src="js/wow.min.js"></script>
<script src="js/jquery.nav.js"></script>
<script src="js/custom.js"></script>
</body>
</html>
